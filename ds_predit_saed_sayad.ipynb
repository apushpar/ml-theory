{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory\n",
    "### Modeling: http://www.saedsayad.com/modeling.htm\n",
    "### Parent link: http://www.saedsayad.com/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictive modeling is the process by which a model is created to predict an outcome. Types:\n",
    "- Categorical outcome: __Classification__ [http://www.saedsayad.com/classification.htm]\n",
    "- Numerical outcome: __Regression__ [http://www.saedsayad.com/regression.htm]\n",
    "- Descriptive modeling or __Clustering__ [http://www.saedsayad.com/clustering.htm]\n",
    "- __Association Rules__: To find interesting associations amongst observations [http://www.saedsayad.com/association_rules.htm]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "1. Frequency table\n",
    "> - ZeroR\n",
    "> - OneR\n",
    "> - Naive Bayesian\n",
    "> - Decision Trees\n",
    "2. Covariance Matrix\n",
    "> - Linear Discriminant Analysis\n",
    "> - Logistic Regression\n",
    "3. Similarity Functions\n",
    "> - KNN\n",
    "4. Others\n",
    "> - Neural Networks\n",
    "> - SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Also refer to the image below taken from scikit learn algo cheat-sheet\n",
    "<img src=\"images/classification.png\" width=\"600px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. ZeroR ...dummy model?\n",
    "- Predicts the most frequent value\n",
    "- Can be used as a baseline\n",
    "- Can only predict the majority class correctly\n",
    "- Algorithm\n",
    "> - Construct a frequency table for the target and select its most frequent value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. OneR\n",
    "- One Rule\n",
    "- Select one of the features(predictor) to predict the target\n",
    "- This one feature should minimize (smallest total error) the total error for predicting the target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Naive Bayesian\n",
    "- Based on Baye's theorm\n",
    "- Assumes that the features/predictors are independent (no correlation)\n",
    "- Assumes the effect of the value of a predictor (x) on a given class is independent of the values of other predictors (called condiditional independence)\n",
    "- Above simplifies the calculation of probabilities\n",
    "- Numerical predictors need to be converted to categorical counterparts via binning\n",
    "- Another way to use Numerical predictors is to assume a distribution (mostly normal distribution) for numerical variables.\n",
    "- Algo\n",
    "\n",
    "<img src=\"images/naive.png\" width=\"500px\">\n",
    "<img src=\"images/naive_eg.png\" width=\"500px\">\n",
    "\n",
    "\n",
    "### side note:\n",
    "> Probability Density Function (pdf) for a normal distribution is defined by the __mean__ and the __standard deviation__\n",
    "> <img src=\"images/pdf.png\" width=\"500px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Decision Tree\n",
    "- Builds model in the form of a tree structure\n",
    "- Dataset is broken down into smaller and smaller subsets while at the same time an associated decision is incremently developed\n",
    "- Final result is a tree with decision nodes and leaf nodes\n",
    "- Can handle both categorical and numerical data\n",
    "\n",
    "<img src=\"images/dt.png\" width=\"800px\">\n",
    "- Core algo for building decision tree is ID3\n",
    "- ID3 has a top down, greedy search of possible branches with no backtracking\n",
    "- ID3 uses __Entropy__ and __Information Gain__ to construct decision tree\n",
    "\n",
    "> ### What is Entropy?\n",
    "> - ID3 uses entropy to calculate the homogeneity (similar values) of a sample\n",
    "> - Sample is completely homogeneous - Entropy = 0\n",
    "> - Sample is equally divided - Entropy = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
